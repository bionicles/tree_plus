TF_FLAGS_EXPECTATION = [
    "TF_DECLARE_FLAG('test_only_experiment_1')",
    "TF_DECLARE_FLAG('test_only_experiment_2')",
    "TF_DECLARE_FLAG('enable_nested_function_shape_inference'):Allow ops such as tf.cond to invoke the ShapeRefiner on their nested functions.",
    "TF_DECLARE_FLAG('enable_quantized_dtypes_training'):Set quantized dtypes, like tf.qint8, to be trainable.",
    "TF_DECLARE_FLAG('graph_building_optimization'):Optimize graph building for faster tf.function tracing.",
    "TF_DECLARE_FLAG('saved_model_fingerprinting'):Add fingerprint to SavedModels.",
    "TF_DECLARE_FLAG('more_stack_traces'):Enable experimental code that preserves and propagates graph node stack traces in C++.",
    "TF_DECLARE_FLAG('publish_function_graphs'):Enables the publication of partitioned function graphs via StatsPublisherInterface. Disabling this flag can reduce memory consumption.",
    "TF_DECLARE_FLAG('enable_aggressive_constant_replication'):Replicate constants across CPU devices and even for local CPUs within the same task if available.",
    "TF_DECLARE_FLAG('enable_colocation_key_propagation_in_while_op_lowering'):If true, colocation key attributes for the ops will be propagated during while op lowering to switch/merge ops.",
    "Flag('tf_xla_auto_jit'):Control compilation of operators into XLA computations on CPU and GPU devices.  0 = use ConfigProto setting; -1 = off; 1 = on for things very likely to be improved; 2 = on for everything; (experimental) fusible = only for Tensorflow operations that XLA knows how to fuse. If set to single-gpu(<N>) then this resolves to <N> for single-GPU graphs (graphs that have at least one node placed on a GPU and no more than one GPU is in use through the entire graph) and 0 otherwise.  Experimental.",
    "Flag('tf_xla_min_cluster_size'):Minimum number of operators in an XLA compilation. Ignored for operators placed on an XLA device or operators explicitly marked for compilation.",
    "Flag('tf_xla_max_cluster_size'):Maximum number of operators in an XLA compilation.",
    "Flag('tf_xla_cluster_exclude_ops'):(experimental) Exclude the operations from auto-clustering. If multiple, separate them with commas. Where, Some_other_ops.",
    "Flag('tf_xla_clustering_debug'):Dump graphs during XLA compilation.",
    "Flag('tf_xla_cpu_global_jit'):Enables global JIT compilation for CPU via SessionOptions.",
    "Flag('tf_xla_clustering_fuel'):Places an artificial limit on the number of ops marked as eligible for clustering.",
    "Flag('tf_xla_disable_deadness_safety_checks_for_debugging'):Disable deadness related safety checks when clustering (this is unsound).",
    "Flag('tf_xla_disable_resource_variable_safety_checks_for_debugging'):Disable resource variables related safety checks when clustering (this is unsound).",
    "Flag('tf_xla_deterministic_cluster_names'):Causes the function names assigned by auto clustering to be deterministic from run to run.",
    "Flag('tf_xla_persistent_cache_directory'):If non-empty, JIT-compiled executables are saved to and loaded from the specified file system directory path. Empty by default.",
    "Flag('tf_xla_persistent_cache_device_types'):If non-empty, the persistent cache will only be used for the specified devices (comma separated). Each device type should be able to be converted to.",
    "Flag('tf_xla_persistent_cache_read_only'):If true, the persistent cache will be read-only.",
    "Flag('tf_xla_disable_strict_signature_checks'):If true, entires loaded into the XLA compile cache will not have their signatures checked strictly. Defaults to false.",
    "Flag('tf_xla_persistent_cache_prefix'):Specifies the persistance cache prefix. Default is.",
    "Flag('tf_xla_sparse_core_disable_table_stacking'):Disable table stacking for all the tables passed to the SparseCore mid level API.",
    "Flag('tf_xla_sparse_core_minibatch_max_division_level'):Max level of division to split input data into minibatches.",
    "Flag('tf_xla_sparse_core_stacking_mem_limit_bytes'):If non-zero, limits the size of the activations for a given table to be below these many bytes.",
    "Flag('tf_xla_sparse_core_stacking_table_shard_limit_bytes'):If non-zero, limits the size of any table shard to be below these many bytes.",
    "Flag('always_specialize')",
    "Flag('cost_driven_async_parallel_for')",
    "Flag('enable_crash_reproducer')",
    "Flag('log_query_of_death')",
    "Flag('vectorize')",
    "Flag('tf_xla_enable_lazy_compilation')",
    "Flag('tf_xla_print_cluster_outputs'):If true then insert Print nodes to print out values produced by XLA clusters.",
    "Flag('tf_xla_check_cluster_input_numerics'):If true then insert CheckNumerics nodes to check all cluster inputs.",
    "Flag('tf_xla_check_cluster_output_numerics'):If true then insert CheckNumerics nodes to check all cluster outputs.",
    "Flag('tf_xla_disable_constant_folding'):If true then disables constant folding on TF graph before XLA compilation.",
    "Flag('tf_xla_disable_full_embedding_pipelining'):If true then disables full embedding pipelining and instead use strict SparseCore / TensorCore sequencing.",
    "Flag('tf_xla_embedding_parallel_iterations'):If >0 then use this many parallel iterations in embedding_pipelining and embedding_sequency. By default, use the parallel_iterations on the original model WhileOp.",
    "Flag('tf_xla_compile_on_demand'):Switch a device into 'on-demand' mode, where instead of autoclustering ops are compiled one by one just-in-time.",
    "Flag('tf_xla_enable_xla_devices'):Generate XLA_* devices, where placing a computation on such a device forces compilation by XLA. Deprecated.",
    "Flag('tf_xla_always_defer_compilation')",
    "Flag('tf_xla_async_compilation'):When lazy compilation is enabled, asynchronous compilation starts the cluster compilation in the background, and the fallback path is executed until the compilation has finished.",
    "Flag('tf_xla_use_device_api_for_xla_launch'):If true, uses Device API (PjRt) for single device compilation and execution of functions marked for JIT compilation i.e. jit_compile=True. Defaults to false.",
    "Flag('tf_xla_use_device_api_for_compile_on_demand'):If true, uses Device API (PjRt) for compiling and executing ops one by one in 'on-demand' mode. Defaults to false.",
    "Flag('tf_xla_use_device_api_for_auto_jit'):If true, uses Device API (PjRt) for compilation and execution when auto-clustering is enabled. Defaults to false.",
    "Flag('tf_xla_use_device_api'):If true, uses Device API (PjRt) for compilation and execution of ops one-by-one in 'on-demand' mode, for functions marked for JIT compilation, or when auto-clustering is enabled. Defaults to false.",
    "Flag('tf_xla_enable_device_api_for_gpu'):If true, uses Device API (PjRt) for TF GPU device. This is a helper flag so that individual tests can turn on PjRt for GPU specifically.",
    "Flag('tf_xla_call_module_disabled_checks'):A comma-sepated list of directives specifying the safety checks to be skipped when compiling XlaCallModuleOp. See the op documentation for the recognized values.",
    "Flag('tf_mlir_enable_mlir_bridge'):Enables experimental MLIR-Based TensorFlow Compiler Bridge.",
    "Flag('tf_mlir_enable_merge_control_flow_pass'):Enables MergeControlFlow pass for MLIR-Based TensorFlow Compiler Bridge.",
    "Flag('tf_mlir_enable_convert_control_to_data_outputs_pass'):Enables MLIR-Based TensorFlow Compiler Bridge.",
    "Flag('tf_mlir_enable_strict_clusters'):Do not allow clusters that have cyclic control dependencies.",
    "Flag('tf_mlir_enable_multiple_local_cpu_devices'):Enable multiple local CPU devices. CPU ops which are outside compiled inside the tpu cluster will also be replicated across multiple cpu devices.",
    "Flag('tf_dump_graphs_in_tfg'):When tf_dump_graphs_in_tfg is true, graphs after transformations are dumped in MLIR TFG dialect and not in GraphDef.",
    "Flag('tf_mlir_enable_generic_outside_compilation'):Enables OutsideCompilation passes for MLIR-Based TensorFlow Generic Compiler Bridge.",
    "Flag('tf_mlir_enable_tpu_variable_runtime_reformatting_pass'):Enables TPUVariableRuntimeReformatting pass for MLIR-Based TensorFlow Compiler Bridge. This enables weight update sharding and creates TPUReshardVariables ops.",
    "TF_PY_DECLARE_FLAG('test_only_experiment_1')",
    "TF_PY_DECLARE_FLAG('test_only_experiment_2')",
    "TF_PY_DECLARE_FLAG('enable_nested_function_shape_inference')",
    "TF_PY_DECLARE_FLAG('enable_quantized_dtypes_training')",
    "TF_PY_DECLARE_FLAG('graph_building_optimization')",
    "TF_PY_DECLARE_FLAG('op_building_optimization')",
    "TF_PY_DECLARE_FLAG('saved_model_fingerprinting')",
    "TF_PY_DECLARE_FLAG('tf_shape_default_int64')",
    "TF_PY_DECLARE_FLAG('more_stack_traces')",
    "TF_PY_DECLARE_FLAG('publish_function_graphs')",
    "TF_PY_DECLARE_FLAG('enable_aggressive_constant_replication')",
    "TF_PY_DECLARE_FLAG('enable_colocation_key_propagation_in_while_op_lowering')",
    "#define TENSORFLOW_CORE_CONFIG_FLAG_DEFS_H_",
    "class Flags",
    "bool SetterForXlaAutoJitFlag(const string& value)",
    "bool SetterForXlaCallModuleDisabledChecks(const string& value)",
    "void AppendMarkForCompilationPassFlagsInternal(std::vector<Flag>* flag_list)",
    "void AllocateAndParseJitRtFlags()",
    "void AllocateAndParseFlags()",
    "void ResetFlags()",
    "bool SetXlaAutoJitFlagFromFlagString(const string& value)",
    "BuildXlaOpsPassFlags* GetBuildXlaOpsPassFlags()",
    "MarkForCompilationPassFlags* GetMarkForCompilationPassFlags()",
    "XlaSparseCoreFlags* GetXlaSparseCoreFlags()",
    "XlaDeviceFlags* GetXlaDeviceFlags()",
    "XlaOpsCommonFlags* GetXlaOpsCommonFlags()",
    "XlaCallModuleFlags* GetXlaCallModuleFlags()",
    "MlirCommonFlags* GetMlirCommonFlags()",
    "void ResetJitCompilerFlags()",
    "const JitRtFlags& GetJitRtFlags()",
    "ConfigProto::Experimental::MlirBridgeRollout GetMlirBridgeRolloutState(    std::optional<const ConfigProto> config_proto)",
    "void AppendMarkForCompilationPassFlags(std::vector<Flag>* flag_list)",
    "void DisableXlaCompilation()",
    "void EnableXlaCompilation()",
    "bool FailOnXlaCompilation()",
    "#define TF_PY_DECLARE_FLAG(flag_name)",
]
