# Tree Plus

A simple command line interface (CLI) tool for developers to show a `tree` enhanced with token counts, line counts, and source code components.

Disclaimer: More languages remain to add, you can find the test cases in the `tests/more_languages` directory.

## Start Quick!

```sh
# Install Tree Plus
# Note: This assumes you already have installed on your machine:
# conda (miniconda3: https://docs.conda.io/en/latest/miniconda.html)
# GitHub CLI (gh: https://cli.github.com/manual/installation)

# Create and activate a conda environment for Python 3.10
conda create --name py310 python=3.10
conda activate py310
```

```sh
# TLDR one liner to install tree_plus:
gh repo clone https://github.com/bionicles/tree_plus.git && cd tree_plus && make cli
```

```sh
# The above is equivalent to:

# Clone the repository
gh repo clone https://github.com/bionicles/tree_plus.git
cd tree_plus

# If you have `make` installed, you can use the Makefile to install `tree_plus`
make cli

# If `make` is not installed, use `pip` instead
# pip install -e .
```

## Usage

```sh
(py310) bion@WIN-QVRBL09D89C:~/hax/tree_plus$ tree_plus tree_plus_src
./src (4761 tokens, 613 lines)
‚îó‚îÅ‚îÅ üìÅ src (4761 tokens, 613 lines)
    ‚î£‚îÅ‚îÅ üìÑ __init__.py (51 tokens, 8 lines)
    ‚î£‚îÅ‚îÅ üìÑ count_tokens_lines.py (327 tokens, 48 lines)
    ‚îÉ   ‚î£‚îÅ‚îÅ class TokenLineCount
    ‚îÉ   ‚î£‚îÅ‚îÅ def count_tokens_lines
    ‚îÉ   ‚îó‚îÅ‚îÅ def count_directory_tokens_lines
    ‚î£‚îÅ‚îÅ üìÑ cli.py (882 tokens, 108 lines)
    ‚îÉ   ‚î£‚îÅ‚îÅ def main
    ‚îÉ   ‚î£‚îÅ‚îÅ def tree_plus
    ‚îÉ   ‚îó‚îÅ‚îÅ def tree_to_string
    ‚î£‚îÅ‚îÅ üìÑ traverse_directory.py (254 tokens, 35 lines)
    ‚îÉ   ‚îó‚îÅ‚îÅ def traverse_directory
    ‚îó‚îÅ‚îÅ üìÑ parse_file.py (3247 tokens, 414 lines)
        ‚î£‚îÅ‚îÅ def parse_file
        ‚î£‚îÅ‚îÅ def extract_nodes
        ‚î£‚îÅ‚îÅ def is_typing_construct
        ‚î£‚îÅ‚îÅ def is_builtin_type
        ‚î£‚îÅ‚îÅ def parse_py
        ‚î£‚îÅ‚îÅ def parse_cobol
        ‚î£‚îÅ‚îÅ def parse_java
        ‚î£‚îÅ‚îÅ def parse_julia
        ‚î£‚îÅ‚îÅ def parse_kotlin
        ‚î£‚îÅ‚îÅ def parse_lisp
        ‚î£‚îÅ‚îÅ def parse_lua
        ‚î£‚îÅ‚îÅ def parse_objective_c
        ‚î£‚îÅ‚îÅ def parse_ocaml
        ‚î£‚îÅ‚îÅ def parse_apl
        ‚î£‚îÅ‚îÅ def parse_matlab
        ‚î£‚îÅ‚îÅ def parse_js
        ‚î£‚îÅ‚îÅ def parse_md
        ‚îó‚îÅ‚îÅ def parse_todo
```

Multiple directories:

```sh
(py310) bion@WIN-QVRBL09D89C:~/hax/tree_plus$ tree_plus tests/more_languages/group1,tests/more_languages/group2
Multiple Directories:
‚î£‚îÅ‚îÅ tests/more_languages/group1 (402 tokens, 88 lines)
‚îÉ   ‚îó‚îÅ‚îÅ üìÅ group1 (402 tokens, 88 lines)
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ KotlinTest.kt (29 tokens, 4 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ data class Person(val name: String)
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ fun greet(person: Person)
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ JavaTest.java (47 tokens, 12 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ class Person
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> Person(String name)
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ class Person -> void greet()
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ LispTest.lisp (31 tokens, 5 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ defstruct person
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ defun greet
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ ObjectiveCTest.m (59 tokens, 16 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ @interface HelloWorld
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ @interface HelloWorld -> (void) sayHello
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ @implementation HelloWorld
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ @implementation HelloWorld -> (void) sayHello
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ void sayHelloWorld()
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ LuaTest.lua (84 tokens, 16 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ function HelloWorld.new
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ function HelloWorld.greet
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ function say_hello
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ JuliaTest.jl (42 tokens, 12 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ module JuliaTest
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ module JuliaTest -> struct Person
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ module JuliaTest -> greet(p::Person)
‚îÉ       ‚î£‚îÅ‚îÅ üìÑ OcamlTest.ml (53 tokens, 12 lines)
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ type color
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ class hello
‚îÉ       ‚îÉ   ‚î£‚îÅ‚îÅ class hello -> method say_hello
‚îÉ       ‚îÉ   ‚îó‚îÅ‚îÅ let main ()
‚îÉ       ‚îó‚îÅ‚îÅ üìÑ COBOL_TEST.CBL (57 tokens, 11 lines)
‚îÉ           ‚î£‚îÅ‚îÅ IDENTIFICATION DIVISION -> PROGRAM-ID. HELLO
‚îÉ           ‚î£‚îÅ‚îÅ DATA DIVISION -> 01 GREETING
‚îÉ           ‚îó‚îÅ‚îÅ PROCEDURE DIVISION
‚îó‚îÅ‚îÅ tests/more_languages/group2 (562 tokens, 117 lines)
    ‚îó‚îÅ‚îÅ üìÅ group2 (562 tokens, 117 lines)
        ‚î£‚îÅ‚îÅ üìÑ ScalaTest.scala (57 tokens, 12 lines)
        ‚î£‚îÅ‚îÅ üìÑ c_test.c (68 tokens, 20 lines)
        ‚î£‚îÅ‚îÅ üìÑ apl_test.apl (44 tokens, 5 lines)
        ‚îÉ   ‚î£‚îÅ‚îÅ :Namespace HelloWorld
        ‚îÉ   ‚î£‚îÅ‚îÅ :Namespace HelloWorld -> hello ‚Üê 'Hello, World!'
        ‚îÉ   ‚îó‚îÅ‚îÅ :Namespace HelloWorld -> plus ‚Üê {‚ç∫+‚çµ}
        ‚î£‚îÅ‚îÅ üìÑ RTest.R (53 tokens, 9 lines)
        ‚î£‚îÅ‚îÅ üìÑ PowershellTest.ps1 (169 tokens, 27 lines)
        ‚îÉ   ‚î£‚îÅ‚îÅ function Test-Ordering($foo)
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> Person($name)
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> Greet()
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> GreetMany($times)
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> NoReturn($times)
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person -> NoReturnNoArgs()
        ‚îÉ   ‚îó‚îÅ‚îÅ function Say-Hello([Person]$person)
        ‚î£‚îÅ‚îÅ üìÑ PhpTest.php (74 tokens, 19 lines)
        ‚îÉ   ‚î£‚îÅ‚îÅ class HelloWorld
        ‚îÉ   ‚î£‚îÅ‚îÅ class HelloWorld -> function sayHello
        ‚îÉ   ‚î£‚îÅ‚îÅ function greet
        ‚îÉ   ‚î£‚îÅ‚îÅ class Person
        ‚îÉ   ‚îó‚îÅ‚îÅ class Person -> function __construct
        ‚î£‚îÅ‚îÅ üìÑ PerlTest.pl (75 tokens, 20 lines)
        ‚îÉ   ‚î£‚îÅ‚îÅ package PerlTest
        ‚îÉ   ‚î£‚îÅ‚îÅ package PerlTest -> sub new
        ‚îÉ   ‚î£‚îÅ‚îÅ package PerlTest -> sub hello
        ‚îÉ   ‚îó‚îÅ‚îÅ package PerlTest -> sub say_hello
        ‚îó‚îÅ‚îÅ üìÑ bash_test.sh (22 tokens, 5 lines)
```

# Software Engineering Prompt(s) (SWE)
- [x] **1. Discuss the Problem, Users, and Ethical Considerations**
  - "AI, let's define the problem we're solving, identify our users, and address any ethical implications of our solution."
- [x] **2. Create and Refine the High-Level Design**
  - "AI, help me create a design document. We need to ensure illegal states are unrepresentable and refine our design based on potential feedback."
- [x] **3. Setup Tools and Define Testing Strategy**
  - "AI, let's identify the tools we need and write unit tests that focus on important behaviors and edge cases."
- [x] **4. Validate System with End-to-End Tests**
  - "AI, let's write end-to-end tests to validate the entire system works from the user's perspective."
- [] **5. Write, Review, and Integrate Code**
  - "AI, let's start writing SOLID code, review it together, and commit it frequently to integrate with the existing codebase."
- [] **6. Document and Get Feedback**
  - "AI, let's update our design document with final details, write user-level documentation, and actively seek out feedback."
- [] **7. Reflect and Learn**
  - "AI, let's conduct a retrospective analysis to learn from our failures and successes."


# 1. Discuss the Problem, Users, and Ethical Considerations

### Problem:
Extend Linux `tree` util to provide a deeper look into contents of Python, JavaScript, Markdown files, and more. It should display software project architecture, major components in the output, and display the number of lines of code and number of OpenAI tokens within each directory and file.

### Goals:
- Extend the capabilities of the existing `tree` command.
- Parse Python, JavaScript, and Markdown files to identify and display major components.
- Calculate and display the number of OpenAI tokens and lines of code in each file and directory.

### Components:
1. **`traverse_directory` Module:** Responsible for traversing through directories and files in a specified location. This will form the base operation similar to the `tree` command.

2. **`parse_file` Module:** Responsible for parsing Python, JavaScript, and Markdown files. It will identify major components in these files.

3. **`count_tokens_lines` Module:** Responsible for counting the number of lines and OpenAI tokens in each file and directory.

3. **`cli` Module:** Responsible for the `click` cli and the `tree_plus` function it invokes to build a `rich.tree.Tree`, and print the tree.

### Data Flow:
- The user provides one or more directories as input.
- `traverse_directory` traverses directories and identifies subdirectories and files.
- For each identified Python, JavaScript, or Markdown file, `parse_file` identifies major components and  `count_tokens_lines`  counts the lines of code and OpenAI tokens.
- The output is organized and displayed to the user by `cli`.

### Potential Refinements Based on Feedback:
This design assumes that the primary goal is to parse specific file types and calculate specific metrics. Feedback might suggest that the tool should be extensible to support more languages, include more metrics, or provide filtering capabilities. Adjustments to the design would be made accordingly.

### Ensuring Illegal States are Unrepresentable:
To ensure illegal states are unrepresentable, we'll validate input paths, handle file reading errors, and safely manage instances where permission to a file or directory is denied. The tool will not attempt to parse unsupported file types.

# 3. Setup Tools and Define Testing Strategy

**Tools Needed:**
- **Python**: The language we will use to build the tool.
- **pyTest**: to write our unit tests and end-to-end tests.
- **GitHub**: A platform for version control where we can commit changes frequently and track the development of the project.
- **CI/CD Pipeline (GitHub Actions)**: For automating tests and ensuring our code is always deployable.
- **click**: To create a command-line interface for the tool.
- **tiktoken**: A Python package for counting OpenAI tokens.
- **rich.tree.Tree**: to display the directory and file hierarchy.

**Testing Strategy:**

1. **Unit Tests**: We will write unit tests for each module and each major function within the modules. Important behaviors and edge cases should be tested. Here are some examples:
    - Test that the File Traversal Module correctly identifies directories and files.
    - Test that the File Parsing Module correctly identifies major components in Python, JavaScript, and Markdown files.
    - Test that the Token Counting Module correctly counts lines of code and OpenAI tokens.
    - Test that errors are handled correctly when encountering unreadable files or directories.

2. **Integration Tests**: These tests will ensure that the modules work correctly together. For example, testing that the File Traversal Module correctly passes files to the File Parsing Module and the Token Counting Module.

3. **End-to-End Tests**: These tests will be written to ensure that the entire system works from the user's perspective. They will simulate real user scenarios, such as passing in multiple directories at once.

4. **Performance Tests**: We will also test how the tool performs with large directory structures to ensure it remains performant and doesn't consume excessive resources.

# Distribution
To distribute your package on PyPI, you'll need to create a PyPI account, then create a source distribution and/or a wheel distribution, then upload your distributions with twine.